{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import torch\n",
    "import numpy as np\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "from tqdm import tqdm\n",
    "from src.helper import after_subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader, model, optimizer, loss):\n",
    "    \"\"\"\n",
    "    Performs one training epoch\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "     # Transfer the model to the GPU\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in tqdm(\n",
    "        enumerate(train_dataloader),\n",
    "        desc=\"Training\",\n",
    "        total=len(train_dataloader),\n",
    "        leave=True,\n",
    "        ncols=80,\n",
    "    ):\n",
    "        # Move data to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # 1. Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "\n",
    "        # 3. Calculate the loss\n",
    "        loss_value = loss(output, target)\n",
    "\n",
    "        # 4. Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss_value.backward()\n",
    "\n",
    "        # 5. Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update average training loss\n",
    "        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss_value.data.item() - train_loss))\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(valid_dataloader, model, loss):\n",
    "    \"\"\"\n",
    "    Validate at the end of one epoch\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        for batch_idx, (data, target) in tqdm(\n",
    "            enumerate(valid_dataloader),\n",
    "            desc=\"Validating\",\n",
    "            total=len(valid_dataloader),\n",
    "            leave=True,\n",
    "            ncols=80,\n",
    "        ):\n",
    "            # Move data to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # 1. Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # 2. Calculate the loss\n",
    "            loss_value = loss(output, target)\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss_value.data.item() - valid_loss))\n",
    "\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\n",
    "    # Initialize tracker for minimum validation loss\n",
    "    if interactive_tracking:\n",
    "        liveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])\n",
    "    else:\n",
    "        liveloss = None\n",
    "\n",
    "    valid_loss_min = None\n",
    "    logs = {}\n",
    "\n",
    "    # Learning rate scheduler: setup a learning rate scheduler that\n",
    "    # Reduces the learning rate when the validation loss reaches a plateau\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        # Training phase\n",
    "        train_loss = train_one_epoch(data_loaders[\"train\"], model, optimizer, loss)\n",
    "\n",
    "        # Validation phase\n",
    "        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\n",
    "\n",
    "        # Print training/validation statistics\n",
    "        print(\n",
    "            \"Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\".format(\n",
    "                epoch, train_loss, valid_loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Early stopping if validation loss is below a threshold\n",
    "        if valid_loss < 0.5:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"Early stopping as validation loss is less than 0.5\")\n",
    "            break\n",
    "\n",
    "        # If the validation loss decreases by more than 1%, save the model\n",
    "        if valid_loss_min is None or ((valid_loss_min - valid_loss) / valid_loss_min > 0.01):\n",
    "            print(f\"New minimum validation loss: {valid_loss:.6f}. Saving model ...\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # Update learning rate using the scheduler\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        # Log the losses and the current learning rate\n",
    "        if interactive_tracking:\n",
    "            logs[\"loss\"] = train_loss\n",
    "            logs[\"val_loss\"] = valid_loss\n",
    "            logs[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_test(test_dataloader, model, loss):\n",
    "    # Monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "\n",
    "        for batch_idx, (data, target) in tqdm(\n",
    "            enumerate(test_dataloader),\n",
    "            desc='Testing',\n",
    "            total=len(test_dataloader),\n",
    "            leave=True,\n",
    "            ncols=80\n",
    "        ):\n",
    "            # Move data to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # 1. Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            logits = model(data)\n",
    "\n",
    "            # 2. Calculate the loss\n",
    "            loss_value = loss(logits, target)\n",
    "\n",
    "            # Update average test loss\n",
    "            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss_value.data.item() - test_loss))\n",
    "\n",
    "            # Convert logits to predicted class\n",
    "            pred = logits.data.max(1, keepdim=True)[1]\n",
    "\n",
    "            # Compare predictions to true label\n",
    "            correct += torch.sum(torch.squeeze(pred.eq(target.data.view_as(pred))).cpu())\n",
    "            total += data.size(0)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "    print(f'\\nTest Accuracy: {100. * correct / total:.2f}% ({correct}/{total})')\n",
    "\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_classify",
   "language": "python",
   "name": "cnn_classfify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
